{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"pytorch-lightning==1.4.5\" \"torchmetrics>=0.3\" \"tensorboard==2.6\" \"torch==1.9\" \"torchvision==0.10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intimate-argument",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Imports"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "PATH_DATASETS = './datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-camping",
   "metadata": {
    "title": "Lit Module with data"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LitMNIST(LightningModule):\n",
    "\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, learning_rate=2e-4, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.example_input_array = torch.randn(1, 28, 28)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.num_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, )),\n",
    "        ])\n",
    "\n",
    "        # Define PyTorch model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def evaluate_batch(self, batch): # Not a lightning method\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return x, y, logits, preds\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, logits, preds = self.evaluate_batch(batch)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, logits, preds = self.evaluate_batch(batch)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        # TODO 0: log test metrics in hparams tab\n",
    "        # https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html#logging-hyperparameters\n",
    "        ...\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        x, y, logits, preds = self.evaluate_batch(batch)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('test_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('test_acc', acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # Test epoch end doc: https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#test-epoch-end\n",
    "\n",
    "        # TODO 2: Log confusion matrix\n",
    "        # https://pytorch.org/docs/stable/tensorboard.html\n",
    "        # https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.TensorBoardLogger.html#pytorch_lightning.loggers.TensorBoardLogger.experiment\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay\n",
    "\n",
    "        # TODO 5: Visualize the images wrongly predicted with the highest confidence\n",
    "        ...\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-demographic",
   "metadata": {
    "title": "Training"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = LitMNIST()\n",
    "\n",
    "# TODO 1: Run the training on a GPU\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#gpus\n",
    "\n",
    "# TODO 3: Save the model weights with the best accuracy\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html#automatic-saving\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint\n",
    "\n",
    "# TODO 4: Log Model Graph in tensorboard\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.loggers.tensorboard.html#pytorch_lightning.loggers.tensorboard.TensorBoardLogger.params.log_graph\n",
    "\n",
    "# TODO 5: Log the profile of a training step in tensorboard \n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/advanced/profiler.html#pytorch-profiling\n",
    "# https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html#use-tensorboard-to-view-results-and-analyze-model-performance\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger=TensorBoardLogger(save_dir='lightning_logs', name='mnist', log_graph=True),\n",
    "    max_epochs=1,\n",
    "    progress_bar_refresh_rate=10,\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-anderson",
   "metadata": {
    "title": "Testing"
   },
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
